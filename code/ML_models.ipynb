{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/clean_data/merged_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - RMSE: 55811.91926540627, R2 Score: -0.12587842411459493\n",
      "Gradient Boosted Trees - RMSE: 55035.11459427612, R2 Score: -0.09475599498089671\n",
      "K-Nearest Neighbors - RMSE: 70744.48544472622, R2 Score: -0.8089341852760377\n",
      "Decision Trees - RMSE: 50935.17759292334, R2 Score: 0.06227988669453488\n",
      "KDE (Regression) - RMSE: 195503.4882239393, R2 Score: -12.814863657048273\n",
      "Linear Regression (PyTorch) - RMSE: 195502.203125, R2 Score: -12.81468234240567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Features and target variable\n",
    "X = df[[\"Avg_temp_june_value\", \"Min_temp_june_value\", \"Precipitation_june_value\", \"Avg_cooling_degree_days_june\"]]\n",
    "y = df[\"total_lyme_disease_counts\"]\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 1. Random Forest\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "rf_preds = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# 2. Gradient Boosted Trees\n",
    "gb_model = GradientBoostingRegressor(random_state=42)\n",
    "gb_model.fit(X_train_scaled, y_train)\n",
    "gb_preds = gb_model.predict(X_test_scaled)\n",
    "\n",
    "# 3. K-Nearest Neighbors\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "knn_preds = knn_model.predict(X_test_scaled)\n",
    "\n",
    "# 4. Decision Trees\n",
    "dt_model = DecisionTreeRegressor(random_state=42)\n",
    "dt_model.fit(X_train_scaled, y_train)\n",
    "dt_preds = dt_model.predict(X_test_scaled)\n",
    "\n",
    "# 5. Bayesian KDE for regression-like task\n",
    "kde = KernelDensity(kernel='gaussian', bandwidth=1.0).fit(X_train_scaled)\n",
    "kde_density = kde.score_samples(X_test_scaled)  # Log-density estimates\n",
    "kde_preds = np.exp(kde_density)  # Convert log-density to probabilities for comparison\n",
    "\n",
    "# 6. PyTorch Linear Regression\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Model initialization\n",
    "input_dim = X_train_tensor.shape[1]\n",
    "lr_model = LinearRegressionModel(input_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(lr_model.parameters(), lr=0.01)\n",
    "\n",
    "# Training\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    lr_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = lr_model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Predictions\n",
    "lr_model.eval()\n",
    "with torch.no_grad():\n",
    "    lr_preds = lr_model(X_test_tensor).numpy().flatten()\n",
    "\n",
    "# Evaluation\n",
    "def evaluate_model(y_true, y_preds, model_name):\n",
    "    rmse = mean_squared_error(y_true, y_preds, squared=False)\n",
    "    r2 = r2_score(y_true, y_preds)\n",
    "    print(f\"{model_name} - RMSE: {rmse}, R2 Score: {r2}\")\n",
    "\n",
    "evaluate_model(y_test, rf_preds, \"Random Forest\")\n",
    "evaluate_model(y_test, gb_preds, \"Gradient Boosted Trees\")\n",
    "evaluate_model(y_test, knn_preds, \"K-Nearest Neighbors\")\n",
    "evaluate_model(y_test, dt_preds, \"Decision Trees\")\n",
    "evaluate_model(y_test, kde_preds, \"KDE (Regression)\")\n",
    "evaluate_model(y_test_tensor.numpy().flatten(), lr_preds, \"Linear Regression (PyTorch)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of these models are very strong at all, but the best performing one appears to be the Decision Tree. Thus, Decision Tree will be used to perform predictions for the number of Lyme disease cases in the year 2042, under RCP 8.5's predicted average temperature, minimum temperature, and average precipitation in the month of June in that year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example new data for 2042\n",
    "new_data = pd.DataFrame({\n",
    "    \"Avg_temp_june_value\": [75.0],  # Replace with projected value for 2042\n",
    "    \"Min_temp_june_value\": [60.0],  # Replace with projected value\n",
    "    \"Precipitation_june_value\": [3.5],  # Replace with projected value\n",
    "    \"Avg_cooling_degree_days_june\": [10.0]  # Replace with projected value\n",
    "})\n",
    "\n",
    "# Scale the new data using the same scaler used for training\n",
    "new_data_scaled = scaler.transform(new_data)\n",
    "\n",
    "# Predict Lyme disease counts for 2042\n",
    "predicted_counts_2042 = dt_model.predict(new_data_scaled)\n",
    "print(\"Predicted total Lyme disease counts in 2042:\", predicted_counts_2042)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
