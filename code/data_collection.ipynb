{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Species richness\n",
    "\n",
    "The cell below takes the geospatial map image of species richness over the United States and allows for manual input of overall state species richness in a tabular format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import pandas as pd\n",
    "\n",
    "class StateDataCollector:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"State Species Richness Data Collector\")\n",
    "        \n",
    "        # Dictionary to store state:value pairs\n",
    "        self.data = {}\n",
    "        \n",
    "        # Create the input frame\n",
    "        input_frame = ttk.Frame(root, padding=\"10\")\n",
    "        input_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
    "        \n",
    "        # Create state selector\n",
    "        self.states = sorted([\n",
    "            'Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado',\n",
    "            'Connecticut', 'Delaware', 'Florida', 'Georgia', 'Hawaii', 'Idaho',\n",
    "            'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana',\n",
    "            'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota',\n",
    "            'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada',\n",
    "            'New Hampshire', 'New Jersey', 'New Mexico', 'New York',\n",
    "            'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon',\n",
    "            'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota',\n",
    "            'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington',\n",
    "            'West Virginia', 'Wisconsin', 'Wyoming'\n",
    "        ])\n",
    "        \n",
    "        self.state_var = tk.StringVar()\n",
    "        state_label = ttk.Label(input_frame, text=\"State:\")\n",
    "        state_label.grid(row=0, column=0, padx=5, pady=5)\n",
    "        state_combo = ttk.Combobox(input_frame, textvariable=self.state_var, values=self.states)\n",
    "        state_combo.grid(row=0, column=1, padx=5, pady=5)\n",
    "        \n",
    "        # Create value input\n",
    "        self.value_var = tk.StringVar()\n",
    "        value_label = ttk.Label(input_frame, text=\"Species Richness (0-15):\")\n",
    "        value_label.grid(row=1, column=0, padx=5, pady=5)\n",
    "        value_entry = ttk.Entry(input_frame, textvariable=self.value_var)\n",
    "        value_entry.grid(row=1, column=1, padx=5, pady=5)\n",
    "        \n",
    "        # Create buttons\n",
    "        button_frame = ttk.Frame(input_frame)\n",
    "        button_frame.grid(row=2, column=0, columnspan=2, pady=10)\n",
    "        \n",
    "        add_button = ttk.Button(button_frame, text=\"Add Entry\", command=self.add_entry)\n",
    "        add_button.grid(row=0, column=0, padx=5)\n",
    "        \n",
    "        save_button = ttk.Button(button_frame, text=\"Save to CSV\", command=self.save_data)\n",
    "        save_button.grid(row=0, column=1, padx=5)\n",
    "        \n",
    "        # Create display area\n",
    "        self.display = tk.Text(input_frame, height=10, width=40)\n",
    "        self.display.grid(row=3, column=0, columnspan=2, pady=10)\n",
    "        \n",
    "    def add_entry(self):\n",
    "        state = self.state_var.get()\n",
    "        value = self.value_var.get()\n",
    "        \n",
    "        if state and value:\n",
    "            try:\n",
    "                value = int(value)\n",
    "                if 0 <= value <= 15:\n",
    "                    self.data[state] = value\n",
    "                    self.update_display()\n",
    "                    # Clear inputs\n",
    "                    self.state_var.set('')\n",
    "                    self.value_var.set('')\n",
    "                else:\n",
    "                    self.display.insert(tk.END, \"Error: Value must be between 0 and 15\\n\")\n",
    "            except ValueError:\n",
    "                self.display.insert(tk.END, \"Error: Please enter a valid number\\n\")\n",
    "    \n",
    "    def update_display(self):\n",
    "        self.display.delete(1.0, tk.END)\n",
    "        for state, value in sorted(self.data.items()):\n",
    "            self.display.insert(tk.END, f\"{state}: {value}\\n\")\n",
    "    \n",
    "    def save_data(self):\n",
    "        df = pd.DataFrame.from_dict(self.data, orient='index', columns=['species_richness'])\n",
    "        df.index.name = 'state'\n",
    "        df.to_csv('../data/raw_data/species_richness_by_state.csv')\n",
    "        self.display.insert(tk.END, \"\\nData saved to species_richness_by_state.csv\\n\")\n",
    "\n",
    "# Create and run the application\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = StateDataCollector(root)\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alabama: 10\n",
    "Arizona: 5\n",
    "Arkansas: 8\n",
    "California: 10\n",
    "Colorado: 2\n",
    "Connecticut: 5\n",
    "Delaware: 5\n",
    "Florida: 9\n",
    "Georgia: 4\n",
    "Idaho: 1\n",
    "Illinois: 6\n",
    "Indiana: 8\n",
    "Iowa: 5\n",
    "Kansas: 1\n",
    "Kentucky: 9\n",
    "Louisiana: 10\n",
    "Maine: 2\n",
    "Maryland: 6\n",
    "Massachusetts: 4\n",
    "Michigan: 3\n",
    "Minnesota: 3\n",
    "Mississippi: 8\n",
    "Missouri: 7\n",
    "Montana: 0\n",
    "Nebraska: 1\n",
    "Nevada: 2\n",
    "New Hampshire: 4\n",
    "New Jersey: 6\n",
    "New Mexico: 1\n",
    "New York: 9\n",
    "North Carolina: 5\n",
    "North Dakota: 1\n",
    "Ohio: 4\n",
    "Oklahoma: 2\n",
    "Oregon: 2\n",
    "Pennsylvania: 6\n",
    "Rhode Island: 4\n",
    "South Carolina: 7\n",
    "South Dakota: 0\n",
    "Tennessee: 11\n",
    "Texas: 3\n",
    "Utah: 3\n",
    "Vermont: 4\n",
    "Virginia: 10\n",
    "Washington: 2\n",
    "West Virginia: 10\n",
    "Wisconsin: 6\n",
    "Wyoming: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \"YAvQVopzQifTCqEDAYkIsFexHiCisBIB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import requests\n",
    "# import time\n",
    "# import logging\n",
    "# from datetime import datetime\n",
    "# from typing import Dict, List, Optional\n",
    "\n",
    "# logging.basicConfig(\n",
    "#     level=logging.INFO,\n",
    "#     format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "# )\n",
    "\n",
    "# class NOAAWeatherCollector:\n",
    "#     def __init__(self, token: str, start_year: int = 2020, end_year: int = 2022):\n",
    "#         self.base_url = \"https://www.ncdc.noaa.gov/cdo-web/api/v2\"\n",
    "#         self.headers = {\"token\": token}\n",
    "#         self.start_year = start_year\n",
    "#         self.end_year = end_year\n",
    "\n",
    "#     def get_weather_data(self, station_id: str, state: str) -> List[Dict]:\n",
    "#         \"\"\"Get weather data for a station\"\"\"\n",
    "#         all_data = []\n",
    "        \n",
    "#         for year in range(self.start_year, self.end_year + 1):\n",
    "#             logging.info(f\"Fetching {year} data for station {station_id}\")\n",
    "            \n",
    "#             params = {\n",
    "#                 \"datasetid\": \"GHCND\",\n",
    "#                 \"stationid\": station_id,\n",
    "#                 \"startdate\": f\"{year}-01-01\",\n",
    "#                 \"enddate\": f\"{year}-12-31\",\n",
    "#                 \"limit\": 1000,\n",
    "#                 \"datatypeid\": \"TMAX,TMIN,PRCP\"  # Temperature max/min and precipitation\n",
    "#             }\n",
    "            \n",
    "#             try:\n",
    "#                 response = requests.get(\n",
    "#                     f\"{self.base_url}/data\",\n",
    "#                     headers=self.headers,\n",
    "#                     params=params\n",
    "#                 )\n",
    "                \n",
    "#                 if response.status_code == 200:\n",
    "#                     data = response.json()\n",
    "#                     if 'results' in data:\n",
    "#                         for record in data['results']:\n",
    "#                             all_data.append({\n",
    "#                                 'station_id': station_id,\n",
    "#                                 'state': state,\n",
    "#                                 'date': record['date'],\n",
    "#                                 'datatype': record['datatype'],\n",
    "#                                 'value': record['value']\n",
    "#                             })\n",
    "#                 elif response.status_code == 429:  # Rate limit\n",
    "#                     wait_time = int(response.headers.get('Retry-After', 60))\n",
    "#                     logging.warning(f\"Rate limit hit. Waiting {wait_time} seconds...\")\n",
    "#                     time.sleep(wait_time)\n",
    "#                 else:\n",
    "#                     logging.error(f\"Error fetching data: {response.status_code}\")\n",
    "                    \n",
    "#             except Exception as e:\n",
    "#                 logging.error(f\"Error processing station {station_id}: {str(e)}\")\n",
    "            \n",
    "#             time.sleep(1)  # Prevent rate limiting\n",
    "            \n",
    "#         return all_data\n",
    "\n",
    "# def process_weather_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "#     \"\"\"Process weather data into yearly averages by state\"\"\"\n",
    "#     # Ensure required columns exist\n",
    "#     required_columns = ['date', 'datatype', 'value', 'state']\n",
    "#     for col in required_columns:\n",
    "#         if col not in df.columns:\n",
    "#             raise KeyError(f\"Missing required column: {col}\")\n",
    "    \n",
    "#     # Convert date to datetime\n",
    "#     df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "#     if df['date'].isnull().any():\n",
    "#         raise ValueError(\"Some 'date' values could not be converted to datetime.\")\n",
    "    \n",
    "#     df['year'] = df['date'].dt.year\n",
    "    \n",
    "#     # Convert values (temperature in tenths of degrees C, precipitation in tenths of mm)\n",
    "#     df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "#     df.loc[df['datatype'].isin(['TMAX', 'TMIN']), 'value'] = df.loc[df['datatype'].isin(['TMAX', 'TMIN']), 'value'] / 10\n",
    "#     df.loc[df['datatype'] == 'PRCP', 'value'] = df.loc[df['datatype'] == 'PRCP', 'value'] / 10\n",
    "    \n",
    "#     # Check for invalid or missing data\n",
    "#     if df.isnull().any().any():\n",
    "#         logging.warning(\"DataFrame contains missing or invalid values. Dropping rows...\")\n",
    "#         df = df.dropna()\n",
    "    \n",
    "#     # Calculate yearly averages by state\n",
    "#     grouped = df.pivot_table(\n",
    "#         index=['state', 'year'],\n",
    "#         columns='datatype',\n",
    "#         values='value',\n",
    "#         aggfunc='mean'\n",
    "#     ).reset_index()\n",
    "    \n",
    "#     # Rename columns\n",
    "#     grouped.columns = ['state', 'year', 'avg_max_temp_c', 'avg_min_temp_c', 'total_precip_mm']\n",
    "    \n",
    "#     return grouped\n",
    "\n",
    "# def main():\n",
    "#     # Read stations from CSV\n",
    "#     stations_df = pd.read_csv('us_weather_stations.csv')\n",
    "    \n",
    "#     # Initialize collector\n",
    "#     token = \"YAvQVopzQifTCqEDAYkIsFexHiCisBIB\"\n",
    "#     collector = NOAAWeatherCollector(token=token)\n",
    "    \n",
    "#     all_weather_data = []\n",
    "    \n",
    "#     # Process a sample of stations first (2 per state)\n",
    "#     sample_stations = stations_df.groupby('state').head(2)\n",
    "    \n",
    "#     for _, station in sample_stations.iterrows():\n",
    "#         try:\n",
    "#             station_data = collector.get_weather_data(\n",
    "#                 station_id=station['id'],\n",
    "#                 state=station['state']\n",
    "#             )\n",
    "#             all_weather_data.extend(station_data)\n",
    "#             logging.info(f\"Collected {len(station_data)} records for {station['id']}\")\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             logging.error(f\"Error processing station {station['id']}: {str(e)}\")\n",
    "#             continue\n",
    "    \n",
    "#     if all_weather_data:\n",
    "#         # Convert to DataFrame\n",
    "#         weather_df = pd.DataFrame(all_weather_data)\n",
    "        \n",
    "#         # Save raw data\n",
    "#         weather_df.to_csv('weather_data_raw.csv', index=False)\n",
    "#         logging.info(\"Saved raw weather data\")\n",
    "        \n",
    "#         # Process and save aggregated data\n",
    "#         state_yearly_df = process_weather_data(weather_df)\n",
    "#         state_yearly_df.to_csv('weather_data_by_state.csv', index=False)\n",
    "#         logging.info(\"Saved processed weather data\")\n",
    "        \n",
    "#         # Display sample of results\n",
    "#         print(\"\\nSample of processed weather data:\")\n",
    "#         print(state_yearly_df.head())\n",
    "#     else:\n",
    "#         logging.error(\"No weather data collected\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     try:\n",
    "#         main()\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"An error occurred: {str(e)}\")\n",
    "#         raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import csv\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# # Define the URL and parameters\n",
    "# url = \"https://www.ncei.noaa.gov/access/monitoring/climate-at-a-glance/statewide/time-series\"\n",
    "# params = {\n",
    "#     \"dataType\": \"avgTemp\",\n",
    "#     \"area\": \"statewide\",\n",
    "#     \"time_scale\": \"monthly\",\n",
    "#     \"month\": \"6\",\n",
    "#     \"state\": \"alabama\",\n",
    "#     \"year\": \"2002\"\n",
    "# }\n",
    "\n",
    "# def state_code_to_state(code):\n",
    "#     # Mapping of state codes to state names\n",
    "#     state_map = {\n",
    "#         1: \"alabama\", 2: \"alaska\", 3: \"arizona\", 4: \"arkansas\", 5: \"california\",\n",
    "#         6: \"colorado\", 7: \"connecticut\", 8: \"delaware\", 9: \"florida\", 10: \"georgia\",\n",
    "#         11: \"hawaii\", 12: \"idaho\", 13: \"illinois\", 14: \"indiana\", 15: \"iowa\",\n",
    "#         16: \"kansas\", 17: \"kentucky\", 18: \"louisiana\", 19: \"maine\", 20: \"maryland\",\n",
    "#         21: \"massachusetts\", 22: \"michigan\", 23: \"minnesota\", 24: \"mississippi\", 25: \"missouri\",\n",
    "#         26: \"montana\", 27: \"nebraska\", 28: \"nevada\", 29: \"new-hampshire\", 30: \"new-jersey\",\n",
    "#         31: \"new-mexico\", 32: \"new-york\", 33: \"north-carolina\", 34: \"north-dakota\", 35: \"ohio\",\n",
    "#         36: \"oklahoma\", 37: \"oregon\", 38: \"pennsylvania\", 39: \"rhode-island\", 40: \"south-carolina\",\n",
    "#         41: \"south-dakota\", 42: \"tennessee\", 43: \"texas\", 44: \"utah\", 45: \"vermont\",\n",
    "#         46: \"virginia\", 47: \"washington\", 48: \"west-virginia\", 49: \"wisconsin\", 50: \"wyoming\"\n",
    "#     }\n",
    "#     return state_map[code]\n",
    "\n",
    "# # Create an empty list to store the data\n",
    "# data = []\n",
    "\n",
    "# # Loop through all 50 states\n",
    "# for state_code in range(1, 51):\n",
    "#     params[\"state\"] = state_code_to_state(state_code)\n",
    "    \n",
    "#     # Loop through the weather parameters\n",
    "#     for param in [\"avgTemp\", \"minTemp\", \"precip\", \"cooling-degree-days\"]:\n",
    "#         params[\"dataType\"] = param\n",
    "        \n",
    "#         # Loop through the years from 2002 to 2022\n",
    "#         for year in range(2002, 2023):\n",
    "#             params[\"year\"] = year\n",
    "            \n",
    "#             # Make the request and parse the HTML\n",
    "#             response = requests.get(url, params=params, timeout=60)\n",
    "#             soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            \n",
    "#             # Find the relevant data elements\n",
    "#             state_name = soup.find(\"h2\").text.split(\":\")[0]\n",
    "#             value = float(soup.find(\"td\", {\"class\": f\"{param.replace('-', '-')}\"}).text)\n",
    "            \n",
    "#             # Add the data to the list\n",
    "#             data.append({\n",
    "#                 \"State\": state_name,\n",
    "#                 \"Year\": year,\n",
    "#                 \"Month\": \"June\",\n",
    "#                 f\"{param.title().replace('-', '_')}_june_value\": value\n",
    "#             })\n",
    "\n",
    "# # Write the data to a CSV file\n",
    "# with open(\"climate_data.csv\", \"w\", newline=\"\") as csvfile:\n",
    "#     fieldnames = [\"State\", \"Year\", \"Month\", \"Avg_temp_june_value\", \"Min_temp_june_value\", \"Precipitation_june_value\", \"Avg_cooling_degree_days_june\"]\n",
    "#     writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "#     writer.writeheader()\n",
    "#     for row in data:\n",
    "#         writer.writerow(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import csv\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# # Define the URL and parameters\n",
    "# url = \"https://www.ncei.noaa.gov/access/monitoring/climate-at-a-glance/statewide/time-series\"\n",
    "# params = {\n",
    "#     \"dataType\": \"avgTemp\",\n",
    "#     \"area\": \"statewide\",\n",
    "#     \"time_scale\": \"monthly\",\n",
    "#     \"month\": \"6\",\n",
    "#     \"state\": \"alabama\",\n",
    "#     \"year\": \"2002\"\n",
    "# }\n",
    "\n",
    "# def state_code_to_state(code):\n",
    "#     # Mapping of state codes to state names\n",
    "#     state_map = {\n",
    "#         1: \"alabama\", 2: \"alaska\", 3: \"arizona\", 4: \"arkansas\", 5: \"california\",\n",
    "#         6: \"colorado\", 7: \"connecticut\", 8: \"delaware\", 9: \"florida\", 10: \"georgia\",\n",
    "#         11: \"hawaii\", 12: \"idaho\", 13: \"illinois\", 14: \"indiana\", 15: \"iowa\",\n",
    "#         16: \"kansas\", 17: \"kentucky\", 18: \"louisiana\", 19: \"maine\", 20: \"maryland\",\n",
    "#         21: \"massachusetts\", 22: \"michigan\", 23: \"minnesota\", 24: \"mississippi\", 25: \"missouri\",\n",
    "#         26: \"montana\", 27: \"nebraska\", 28: \"nevada\", 29: \"new-hampshire\", 30: \"new-jersey\",\n",
    "#         31: \"new-mexico\", 32: \"new-york\", 33: \"north-carolina\", 34: \"north-dakota\", 35: \"ohio\",\n",
    "#         36: \"oklahoma\", 37: \"oregon\", 38: \"pennsylvania\", 39: \"rhode-island\", 40: \"south-carolina\",\n",
    "#         41: \"south-dakota\", 42: \"tennessee\", 43: \"texas\", 44: \"utah\", 45: \"vermont\",\n",
    "#         46: \"virginia\", 47: \"washington\", 48: \"west-virginia\", 49: \"wisconsin\", 50: \"wyoming\"\n",
    "#     }\n",
    "#     return state_map[code]\n",
    "\n",
    "# # Create an empty list to store the data\n",
    "# data = []\n",
    "\n",
    "# # Loop through all 50 states\n",
    "# for state_code in range(1, 51):\n",
    "#     params[\"state\"] = state_code_to_state(state_code)\n",
    "    \n",
    "#     # Loop through the weather parameters\n",
    "#     for param in [\"avgTemp\", \"minTemp\", \"precip\", \"cooling-degree-days\"]:\n",
    "#         params[\"dataType\"] = param\n",
    "        \n",
    "#         # Loop through the years from 2002 to 2022\n",
    "#         for year in range(2002, 2023):\n",
    "#             params[\"year\"] = year\n",
    "            \n",
    "#             # Make the request and parse the HTML\n",
    "#             response = requests.get(url, params=params)\n",
    "#             soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            \n",
    "#             # Find the relevant data elements\n",
    "#             state_name = soup.find(\"h2\")\n",
    "#             if state_name:\n",
    "#                 state_name = state_name.text.split(\":\")[0]\n",
    "#             else:\n",
    "#                 state_name = \"Unknown\"\n",
    "            \n",
    "#             value_element = soup.find(\"td\", {\"class\": f\"{param.replace('-', '-')}\"})\n",
    "#             if value_element:\n",
    "#                 value = float(value_element.text)\n",
    "#             else:\n",
    "#                 value = float(\"nan\")\n",
    "            \n",
    "#             # Add the data to the list\n",
    "#             data.append({\n",
    "#                 \"State\": state_name,\n",
    "#                 \"Year\": year,\n",
    "#                 \"Month\": \"June\",\n",
    "#                 f\"{param.title().replace('-', '_')}_june_value\": value\n",
    "#             })\n",
    "\n",
    "# # Write the data to a CSV file\n",
    "# with open(\"climate_data.csv\", \"w\", newline=\"\") as csvfile:\n",
    "#     fieldnames = [\"State\", \"Year\", \"Month\", \"Avg_temp_june_value\", \"Min_temp_june_value\", \"Precipitation_june_value\", \"Avg_cooling_degree_days_june\"]\n",
    "#     writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "#     writer.writeheader()\n",
    "#     for row in data:\n",
    "#         writer.writerow(row)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
