{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:70: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:70: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/var/folders/0s/3s0t3s4d31d4xtm_jt4pfhpr0000gn/T/ipykernel_11633/967449051.py:70: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  df_clean['State'] = df_clean['State'].str.replace('[^a-zA-Z\\s]', '', regex=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying latin1 encoding...\n",
      "Successfully read file with latin1 encoding\n",
      "\n",
      "First few rows of the cleaned dataset:\n",
      "        State  Year  Lyme_cases   region\n",
      "13   Illinois  2008         108  central\n",
      "65   Illinois  2009         136  central\n",
      "117  Illinois  2010         135  central\n",
      "169  Illinois  2011         194  central\n",
      "221  Illinois  2012         204  central\n",
      "\n",
      "Unique state names after cleaning:\n",
      "['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut', 'Delaware', 'District of Columbia', 'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee', 'Texas', 'US Total', 'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia', 'Wisconsin', 'Wyoming']\n",
      "\n",
      "Summary of data by region:\n",
      "          Number of States\n",
      "region                    \n",
      "central                 12\n",
      "eastern                 12\n",
      "southern                12\n",
      "western                 13\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_region_mapping():\n",
    "    \"\"\"Create dictionary mapping states to their regions\"\"\"\n",
    "    return {\n",
    "        # [Your existing region mapping dictionary stays the same]\n",
    "        # Northeast/Eastern Region\n",
    "        'Maine': 'eastern',\n",
    "        'New Hampshire': 'eastern',\n",
    "        'Vermont': 'eastern',\n",
    "        'Massachusetts': 'eastern',\n",
    "        'Rhode Island': 'eastern',\n",
    "        'Connecticut': 'eastern',\n",
    "        'New York': 'eastern',\n",
    "        'Pennsylvania': 'eastern',\n",
    "        'New Jersey': 'eastern',\n",
    "        'Delaware': 'eastern',\n",
    "        'Maryland': 'eastern',\n",
    "        'District of Columbia': 'eastern',\n",
    "        \n",
    "        # Southern Region\n",
    "        'Virginia': 'southern',\n",
    "        'West Virginia': 'southern',\n",
    "        'Kentucky': 'southern',\n",
    "        'Tennessee': 'southern',\n",
    "        'North Carolina': 'southern',\n",
    "        'South Carolina': 'southern',\n",
    "        'Georgia': 'southern',\n",
    "        'Florida': 'southern',\n",
    "        'Alabama': 'southern',\n",
    "        'Mississippi': 'southern',\n",
    "        'Louisiana': 'southern',\n",
    "        'Arkansas': 'southern',\n",
    "        \n",
    "        # Central Region\n",
    "        'Ohio': 'central',\n",
    "        'Indiana': 'central',\n",
    "        'Illinois': 'central',\n",
    "        'Michigan': 'central',\n",
    "        'Wisconsin': 'central',\n",
    "        'Minnesota': 'central',\n",
    "        'Iowa': 'central',\n",
    "        'Missouri': 'central',\n",
    "        'North Dakota': 'central',\n",
    "        'South Dakota': 'central',\n",
    "        'Nebraska': 'central',\n",
    "        'Kansas': 'central',\n",
    "        \n",
    "        # Western Region\n",
    "        'Montana': 'western',\n",
    "        'Idaho': 'western',\n",
    "        'Wyoming': 'western',\n",
    "        'Colorado': 'western',\n",
    "        'New Mexico': 'western',\n",
    "        'Arizona': 'western',\n",
    "        'Utah': 'western',\n",
    "        'Nevada': 'western',\n",
    "        'California': 'western',\n",
    "        'Oregon': 'western',\n",
    "        'Washington': 'western',\n",
    "        'Alaska': 'western',\n",
    "        'Hawaii': 'western'\n",
    "    }\n",
    "\n",
    "def clean_lyme_data(df):\n",
    "    # Create copy of dataframe\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Clean state names by removing unusual characters\n",
    "    df_clean['State'] = df_clean['State'].str.replace('[^a-zA-Z\\s]', '', regex=True)\n",
    "    \n",
    "    # Melt the dataframe to convert years to rows\n",
    "    df_melted = pd.melt(\n",
    "        df_clean,\n",
    "        id_vars=['State'],\n",
    "        var_name='Year',\n",
    "        value_name='Lyme_cases'\n",
    "    )\n",
    "    \n",
    "    # Create region mapping\n",
    "    region_mapping = create_region_mapping()\n",
    "    \n",
    "    # Add region column\n",
    "    df_melted['region'] = df_melted['State'].map(region_mapping)\n",
    "    \n",
    "    # Convert Year to integer\n",
    "    df_melted['Year'] = pd.to_numeric(df_melted['Year'])\n",
    "    \n",
    "    # Sort by region, state, and year\n",
    "    df_melted = df_melted.sort_values(['region', 'State', 'Year'])\n",
    "\n",
    "    df_melted['Lyme_cases'] = df_melted['Lyme_cases'].str.replace(',', '').astype(int)\n",
    "    \n",
    "    return df_melted\n",
    "\n",
    "# Initialize df as None before the loop\n",
    "df = None\n",
    "\n",
    "# Try different encodings until one works\n",
    "encodings_to_try = ['latin1', 'cp1252', 'iso-8859-1', 'utf-8']\n",
    "for encoding in encodings_to_try:\n",
    "    try:\n",
    "        print(f\"Trying {encoding} encoding...\")\n",
    "        df = pd.read_csv('../data/raw_data/lyme_states_2008-2022_WIDE.csv', encoding=encoding)\n",
    "        print(f\"Successfully read file with {encoding} encoding\")\n",
    "        break\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Failed with {encoding} encoding\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"Different error with {encoding} encoding: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Check if we successfully loaded the data\n",
    "if df is None:\n",
    "    raise Exception(\"Could not read the CSV file with any of the attempted encodings\")\n",
    "\n",
    "# Clean the data\n",
    "state_lyme = clean_lyme_data(df)\n",
    "\n",
    "# Display first few rows and basic information\n",
    "print(\"\\nFirst few rows of the cleaned dataset:\")\n",
    "print(state_lyme.head())\n",
    "\n",
    "# Print unique state names to verify cleaning worked\n",
    "print(\"\\nUnique state names after cleaning:\")\n",
    "print(sorted(state_lyme['State'].unique()))\n",
    "\n",
    "print(\"\\nSummary of data by region:\")\n",
    "print(state_lyme.groupby('region')['State'].nunique().to_frame('Number of States'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing average temperature data..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "../data/raw_data/western_avgtemp.csv\n",
      "../data/raw_data/central_avgtemp.csv\n",
      "../data/raw_data/eastern_avgtemp.csv\n",
      "../data/raw_data/southern_avgtemp.csv\n",
      "\n",
      "Processing ../data/raw_data/western_avgtemp.csv\n",
      "Extracted region: western\n",
      "Read 21 rows from file\n",
      "Successfully processed ../data/raw_data/western_avgtemp.csv\n",
      "\n",
      "Processing ../data/raw_data/central_avgtemp.csv\n",
      "Extracted region: central\n",
      "Read 21 rows from file\n",
      "Successfully processed ../data/raw_data/central_avgtemp.csv\n",
      "\n",
      "Processing ../data/raw_data/eastern_avgtemp.csv\n",
      "Extracted region: eastern\n",
      "Read 21 rows from file\n",
      "Successfully processed ../data/raw_data/eastern_avgtemp.csv\n",
      "\n",
      "Processing ../data/raw_data/southern_avgtemp.csv\n",
      "Extracted region: southern\n",
      "Read 21 rows from file\n",
      "Successfully processed ../data/raw_data/southern_avgtemp.csv\n",
      "\n",
      "Processing minimum temperature data...\n",
      "\n",
      "Found these mintemp files:\n",
      "../data/raw_data/western_mintemp.csv\n",
      "../data/raw_data/southern_mintemp.csv\n",
      "../data/raw_data/eastern_mintemp.csv\n",
      "../data/raw_data/central_mintemp.csv\n",
      "\n",
      "Processing ../data/raw_data/western_mintemp.csv\n",
      "Extracted region: western\n",
      "Read 15 rows from file\n",
      "Successfully processed ../data/raw_data/western_mintemp.csv\n",
      "\n",
      "Processing ../data/raw_data/southern_mintemp.csv\n",
      "Extracted region: southern\n",
      "Read 15 rows from file\n",
      "Successfully processed ../data/raw_data/southern_mintemp.csv\n",
      "\n",
      "Processing ../data/raw_data/eastern_mintemp.csv\n",
      "Extracted region: eastern\n",
      "Read 15 rows from file\n",
      "Successfully processed ../data/raw_data/eastern_mintemp.csv\n",
      "\n",
      "Processing ../data/raw_data/central_mintemp.csv\n",
      "Extracted region: central\n",
      "Read 15 rows from file\n",
      "Successfully processed ../data/raw_data/central_mintemp.csv\n",
      "\n",
      "Processing processing data...\n",
      "../data/raw_data/western_precipitation.csv\n",
      "../data/raw_data/central_precipitation.csv\n",
      "../data/raw_data/eastern_precipitation.csv\n",
      "../data/raw_data/southern_precipitation.csv\n",
      "\n",
      "Processing ../data/raw_data/western_precipitation.csv\n",
      "Extracted region: western\n",
      "Read 15 rows from file\n",
      "Successfully processed ../data/raw_data/western_precipitation.csv\n",
      "\n",
      "Processing ../data/raw_data/central_precipitation.csv\n",
      "Extracted region: central\n",
      "Read 15 rows from file\n",
      "Successfully processed ../data/raw_data/central_precipitation.csv\n",
      "\n",
      "Processing ../data/raw_data/eastern_precipitation.csv\n",
      "Extracted region: eastern\n",
      "Read 15 rows from file\n",
      "Successfully processed ../data/raw_data/eastern_precipitation.csv\n",
      "\n",
      "Processing ../data/raw_data/southern_precipitation.csv\n",
      "Extracted region: southern\n",
      "Read 15 rows from file\n",
      "Successfully processed ../data/raw_data/southern_precipitation.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def clean_avgtemp_data():\n",
    "    \n",
    "    # List to store dataframes\n",
    "    avg_dfs = []\n",
    "    \n",
    "    # find all avgtemp data for each region\n",
    "    avgtemp_files = glob.glob(\"../data/raw_data/*avgtemp.csv\")  \n",
    "    for file in avgtemp_files:\n",
    "        print(file)\n",
    "    \n",
    "    # Process each avgtemp file for the regions\n",
    "    for file_path in avgtemp_files:\n",
    "        print(f\"\\nProcessing {file_path}\")\n",
    "        # Extract region from filename\n",
    "        region = os.path.basename(file_path).split('_')[0]\n",
    "        print(f\"Extracted region: {region}\")\n",
    "        \n",
    "        try:\n",
    "            # Read CSV file, skipping the first 4 rows\n",
    "            df = pd.read_csv(file_path, skiprows=4)\n",
    "            print(f\"Read {len(df)} rows from file\")\n",
    "            \n",
    "            # Clean and rename columns\n",
    "            df = df[['Date', 'Value']]  # Keep only needed columns\n",
    "            df = df.rename(columns={\n",
    "                'Date': 'Year',\n",
    "                'Value': 'Avg_temp'\n",
    "            })\n",
    "            \n",
    "            # Extract year from the date column\n",
    "            df['Year'] = df['Year'].astype(str).str[:4].astype(int)\n",
    "            \n",
    "            # Add region column\n",
    "            df['region'] = region\n",
    "            \n",
    "            avg_dfs.append(df)\n",
    "            print(f\"Successfully processed {file_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {str(e)}\")\n",
    "    \n",
    "    # Combine all regions\n",
    "    if avg_dfs:\n",
    "        return pd.concat(avg_dfs, ignore_index=True)\n",
    "    return None\n",
    "\n",
    "def clean_mintemp_data():\n",
    "    # List to store dataframes\n",
    "    min_dfs = []\n",
    "    \n",
    "    # Show which files we're finding\n",
    "    print(\"\\nFound these mintemp files:\")\n",
    "    mintemp_files = glob.glob(\"../data/raw_data/*mintemp.csv\")  # Removed underscore from pattern\n",
    "    for file in mintemp_files:\n",
    "        print(file)\n",
    "    \n",
    "    # Process each mintemp file for the regions\n",
    "    for file_path in mintemp_files:\n",
    "        print(f\"\\nProcessing {file_path}\")\n",
    "        # Extract region from filename\n",
    "        region = os.path.basename(file_path).split('_')[0]\n",
    "        print(f\"Extracted region: {region}\")\n",
    "        \n",
    "        try:\n",
    "            # Read CSV file, skipping the first 4 rows\n",
    "            df = pd.read_csv(file_path, skiprows=4)\n",
    "            print(f\"Read {len(df)} rows from file\")\n",
    "            \n",
    "            # Clean and rename columns\n",
    "            df = df[['Date', 'Value']]  # Keep only needed columns\n",
    "            df = df.rename(columns={\n",
    "                'Date': 'Year',\n",
    "                'Value': 'Min_temp_avg'\n",
    "            })\n",
    "            \n",
    "            # Extract year from the date column\n",
    "            df['Year'] = df['Year'].astype(str).str[:4].astype(int)\n",
    "            \n",
    "            # Add region column\n",
    "            df['region'] = region\n",
    "            \n",
    "            min_dfs.append(df)\n",
    "            print(f\"Successfully processed {file_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {str(e)}\")\n",
    "    \n",
    "    # Combine all regions\n",
    "    if min_dfs:\n",
    "        return pd.concat(min_dfs, ignore_index=True)\n",
    "    return None\n",
    "\n",
    "\n",
    "# PRECIPITATION DATA\n",
    "def clean_precipitation_data():\n",
    "    # List to store dataframes\n",
    "    min_dfs = []\n",
    "    \n",
    "    # Show which files we're finding\n",
    "    precipitation_files = glob.glob(\"../data/raw_data/*precipitation.csv\")  # Removed underscore from pattern\n",
    "    for file in precipitation_files:\n",
    "        print(file)\n",
    "    \n",
    "    # Process each mintemp file for the regions\n",
    "    for file_path in precipitation_files:\n",
    "        print(f\"\\nProcessing {file_path}\")\n",
    "        # Extract region from filename\n",
    "        region = os.path.basename(file_path).split('_')[0]\n",
    "        print(f\"Extracted region: {region}\")\n",
    "        \n",
    "        try:\n",
    "            # Read CSV file, skipping the first 4 rows\n",
    "            df = pd.read_csv(file_path, skiprows=4)\n",
    "            print(f\"Read {len(df)} rows from file\")\n",
    "            \n",
    "            # Clean and rename columns\n",
    "            df = df[['Date', 'Value']]  # Keep only needed columns\n",
    "            df = df.rename(columns={\n",
    "                'Date': 'Year',\n",
    "                'Value': 'Precipitation_avg'\n",
    "            })\n",
    "            \n",
    "            # Extract year from the date column\n",
    "            df['Year'] = df['Year'].astype(str).str[:4].astype(int)\n",
    "            \n",
    "            # Add region column\n",
    "            df['region'] = region\n",
    "            \n",
    "            min_dfs.append(df)\n",
    "            print(f\"Successfully processed {file_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {str(e)}\")\n",
    "    \n",
    "    # Combine all regions\n",
    "    if min_dfs:\n",
    "        return pd.concat(min_dfs, ignore_index=True)\n",
    "    return None\n",
    "\n",
    "# Process both types of data\n",
    "print(\"Processing average temperature data...\")\n",
    "avg_temp_data = clean_avgtemp_data()\n",
    "print(\"\\nProcessing minimum temperature data...\")\n",
    "min_temp_data = clean_mintemp_data()\n",
    "print(\"\\nProcessing processing data...\")\n",
    "precipitation_data = clean_precipitation_data()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Merge average and minimum temperature data\n",
    "# if avg_temp_data is not None and min_temp_data is not None:\n",
    "#     final_data = min_temp_data.merge(avg_temp_data, on=['year', 'region'], how='left')\n",
    "    \n",
    "#     # Sort by region and year\n",
    "#     final_data = final_data.sort_values(['region', 'year'])\n",
    "    \n",
    "#     # Save the merged dataset\n",
    "#     final_data.to_csv(\"merged_temperature_data.csv\", index=False)\n",
    "    \n",
    "#     print(\"\\nData processing completed successfully!\")\n",
    "#     print(\"\\nFirst few rows of the merged dataset:\")\n",
    "#     print(final_data.head())\n",
    "# else:\n",
    "#     print(\"Error: No data was processed. Please check if the input files exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      State  Year  Lyme_cases   region  Precipitation_avg  Min_temp_avg  \\\n",
      "0  Illinois  2008         108  central               4.49          53.8   \n",
      "1   Indiana  2008          42  central               4.49          53.8   \n",
      "2      Iowa  2008         109  central               4.49          53.8   \n",
      "3    Kansas  2008          16  central               4.49          53.8   \n",
      "4  Michigan  2008          92  central               4.49          53.8   \n",
      "\n",
      "   Avg_temp  \n",
      "0      66.1  \n",
      "1      66.1  \n",
      "2      66.1  \n",
      "3      66.1  \n",
      "4      66.1  \n"
     ]
    }
   ],
   "source": [
    "merged = min_temp_data.merge(avg_temp_data, on=['Year', 'region'], how='left')\n",
    "merged2 = precipitation_data.merge(merged, on=['Year', 'region'], how='outer')\n",
    "merged3 = state_lyme.merge(merged2, on=['Year', 'region'], how='right')\n",
    "print(merged3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged3.to_csv('../data/clean_data/state_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
